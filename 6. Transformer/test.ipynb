{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.layers import make_model\n",
    "from transformer.utils import subsequent_mask, tokenize, detokenize, split_tokens\n",
    "from transformer.layers import EncoderDecoder\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import torch, unicodedata\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_data = torch.load('../5. Embedding/embedding_base.h5')\n",
    "# model_data = torch.load('./model_base.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_embedding(embedding_file, model_data) -> tuple[EncoderDecoder, dict, list]:\n",
    "    embedding_data = torch.load(embedding_file, map_location=torch.device(DEVICE))\n",
    "    model_data = torch.load(model_data, map_location=torch.device(DEVICE))\n",
    "    model = make_model(\n",
    "        SRC_VOCAB_LEN,\n",
    "        DST_VOCAB_LEN,\n",
    "        N=N, d_ff=D_FF, h=HEAD, dropout=DROPOUT,\n",
    "        d_model=EMBEDDING_SIZE,\n",
    "        device=DEVICE,\n",
    "    ).eval()\n",
    "    model.load_state_dict(model_data['model_state'])\n",
    "    model.eval()\n",
    "    mad_tokens = {x:i for i,x in enumerate(embedding_data['MAD']['token'])}\n",
    "    ind_tokens = [x for i,x in enumerate(embedding_data['IND']['token'])]\n",
    "    return model, mad_tokens, ind_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(src_teks: list[str], model_data: tuple[EncoderDecoder, dict, list], debug=False) -> list[str]:\n",
    "    model, mad_tokens, ind_tokens = model_data\n",
    "    src = tokenize(src_teks, mad_tokens, wordpiece=True, debug=debug)\n",
    "    src_mask = (src != 2).unsqueeze(-2)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.zeros(1, 1).type_as(src)\n",
    "    for i in range(100):\n",
    "            out = model.decode(\n",
    "                memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "            )\n",
    "            prob = model.generator(out[:, -1])\n",
    "            _, next_word = torch.max(prob, dim=1)\n",
    "            next_word = next_word.data[0]\n",
    "            ys = torch.cat(\n",
    "                [ys, torch.empty(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "            )\n",
    "            if next_word == 1:\n",
    "                break\n",
    "    return detokenize(ys, ind_tokens, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests, truths = [], []\n",
    "with open('../7. Testing/data.txt', 'r', encoding='utf8') as f:\n",
    "    while True:\n",
    "        t, t2 = f.readline(), f.readline()\n",
    "        if not t or not t2:\n",
    "            break\n",
    "        tests.append(unicodedata.normalize('NFKD', t).strip().lower().replace('q', \"'\"))\n",
    "        truths.append([split_tokens(t2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, tests, truths, output):\n",
    "    predicts = []\n",
    "    for i in tqdm(range(len(tests))):\n",
    "        predicts.append(split_tokens(translate([tests[i]], model)[0]))\n",
    "    with open(output, 'w', encoding='utf8') as f:\n",
    "        for i in range(1, 5):\n",
    "            f.write(f'BLEU w/ n-gram {i} : \\\n",
    "                {bleu_score(predicts, truths,max_n=i, weights=[1/i]*i)*100}\\\n",
    "            \\n')\n",
    "        f.write('\\n')\n",
    "        for i in range(len(predicts)):\n",
    "            f.write(f'Question: {tests[i]}\\n')\n",
    "            f.write(f'Truth   : {\" \".join(truths[i][0])}\\n')\n",
    "            f.write(f'Answer  : {\" \".join(predicts[i])}\\n')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:32<00:00,  8.73it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE, EPOCH, EMBEDDING_SIZE, PAD_TOKEN, DEVICE = 200, 500, 512, 2, 'cpu'\n",
    "N, D_FF, HEAD, DROPOUT, LABEL_SMOOTHING, LR_MODE = 6, 2048, 8, 0.1, 0.1, 'warmup'\n",
    "SRC_VOCAB_LEN, DST_VOCAB_LEN = 30994, 14972\n",
    "model = load_model_embedding('../5. Embedding/embedding_base.h5', './model_high_base.h5')\n",
    "test_model(model, tests, truths, './result_high_base.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE, EPOCH, EMBEDDING_SIZE, PAD_TOKEN, DEVICE = 200, 500, 512, 2, 'cpu'\n",
    "N, D_FF, HEAD, DROPOUT, LABEL_SMOOTHING, LR_MODE = 6, 2048, 8, 0.1, 0.1, 'warmup'\n",
    "SRC_VOCAB_LEN, DST_VOCAB_LEN = 8004, 8004\n",
    "model = load_model_embedding('../5. Embedding/embedding_wp8k.h5', \n",
    "'./model_high_wp8k.h5')\n",
    "# test_model(model, tests, truths, './result_high_wp8k.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:45<00:00,  6.20it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE, EPOCH, EMBEDDING_SIZE, PAD_TOKEN, DEVICE = 200, 500, 256, 2, 'cpu'\n",
    "N, D_FF, HEAD, DROPOUT, LABEL_SMOOTHING, LR_MODE = 6, 2048, 2, 0.3, 0.1, 'decay'\n",
    "SRC_VOCAB_LEN, DST_VOCAB_LEN = 30994, 14972\n",
    "model = load_model_embedding('../5. Embedding/embedding_base.h5', './model_low_base.h5')\n",
    "test_model(model, tests, truths, './result_low_base.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:03<00:00, 77.39it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE, EPOCH, EMBEDDING_SIZE, PAD_TOKEN, DEVICE = 200, 500, 256, 2, 'cpu'\n",
    "N, D_FF, HEAD, DROPOUT, LABEL_SMOOTHING, LR_MODE = 6, 2048, 2, 0.3, 0.1, 'decay'\n",
    "SRC_VOCAB_LEN, DST_VOCAB_LEN = 8004, 8004\n",
    "model = load_model_embedding('../5. Embedding/embedding_wp8k.h5', './model_low_wp8k.h5')\n",
    "test_model(model, tests, truths, './result_low_wp8k.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_tokenized ['[UNK]', 'è', '[UNK]', 'tèdung', \"sèngko'\"]\n",
      "src_indexed [0, 3, 100, 3, 10752, 19, 1]\n",
      "dst_indexed tensor([ 0, 16,  1])\n",
      "dst_tokenized ['saya']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['saya']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate([\"dâpa' è dissa' tèdung sèngko'\"], model, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total known words: 486\n",
      "Total unknown words: 393\n",
      "Total words: 879\n",
      "Average words per sentence: 5.816901408450704, Max words: 28, Min words: 1\n",
      "Percentage of unknown words: 27.72397094430993%, 458 of 1652 words\n",
      "Percentage of sentences with unknown words: 80.98591549295774%, 230 of 284 sentences\n"
     ]
    }
   ],
   "source": [
    "# Find total unknown words\n",
    "known_words, unknown_words, words_len, count_unk, count_tot, count_cov = set(), set(), list(), 0, 0, 0\n",
    "for test in tests:\n",
    "    words = split_tokens(test)\n",
    "    words_len.append(len(words))\n",
    "    has_unk = False\n",
    "    for word in words:\n",
    "        count_tot += 1\n",
    "        if word.encode('utf-8') in model[1]:\n",
    "            known_words.add(word)\n",
    "        else:\n",
    "            count_unk += 1\n",
    "            unknown_words.add(word)\n",
    "            has_unk = True\n",
    "    if has_unk:\n",
    "        count_cov += 1\n",
    "print(f'Total known words: {len(known_words)}')\n",
    "print(f'Total unknown words: {len(unknown_words)}')\n",
    "print(f'Total words: {len(known_words) + len(unknown_words)}')\n",
    "print(f'Average words per sentence: {sum(words_len)/len(words_len)}, Max words: {max(words_len)}, Min words: {min(words_len)}')\n",
    "print(f'Percentage of unknown words: {count_unk/count_tot*100}%, {count_unk} of {count_tot} words')\n",
    "print(f'Percentage of sentences with unknown words: {count_cov/len(tests)*100}%, {count_cov} of {len(tests)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.552901023890785"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "486/879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('torch_m1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "119f89536cc47397180d31b7571c1053f63887a15e8165a80c120a7a49737c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
