{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.utils import subsequent_mask, tokenize, detokenize, split_tokens\n",
    "from transformer.layers import EncoderDecoder, make_model\n",
    "from transformer.train import data_gen\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from torchinfo import summary\n",
    "import torch, unicodedata\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_data = torch.load('../5. Embedding/embedding_base.h5')\n",
    "# model_data = torch.load('./model_base.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_embedding(embedding_file, model_data) -> tuple[EncoderDecoder, dict, list]:\n",
    "    embedding_data = torch.load(embedding_file, map_location=torch.device(DEVICE))\n",
    "    model_data = torch.load(model_data, map_location=torch.device(DEVICE))\n",
    "    model = make_model(\n",
    "        SRC_VOCAB_LEN,\n",
    "        DST_VOCAB_LEN,\n",
    "        N=N, d_ff=D_FF, h=HEAD, dropout=DROPOUT,\n",
    "        d_model=EMBEDDING_SIZE,\n",
    "        device=DEVICE,\n",
    "    ).eval()\n",
    "    model.load_state_dict(model_data['model_state'])\n",
    "    model.eval()\n",
    "    mad_tokens = {x:i for i,x in enumerate(embedding_data['MAD']['token'])}\n",
    "    ind_tokens = [x for i,x in enumerate(embedding_data['IND']['token'])]\n",
    "    return model, mad_tokens, ind_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(src_teks: list[str], model_data: tuple[EncoderDecoder, dict, list], debug=False) -> list[str]:\n",
    "    model, mad_tokens, ind_tokens = model_data\n",
    "    src = tokenize(src_teks, mad_tokens, wordpiece=True, debug=debug)\n",
    "    src_mask = (src != 2).unsqueeze(-2)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.zeros(1, 1).type_as(src)\n",
    "    for i in range(100):\n",
    "            out = model.decode(\n",
    "                memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "            )\n",
    "            prob = model.generator(out[:, -1])\n",
    "            _, next_word = torch.max(prob, dim=1)\n",
    "            next_word = next_word.data[0]\n",
    "            ys = torch.cat(\n",
    "                [ys, torch.empty(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "            )\n",
    "            if next_word == 1:\n",
    "                break\n",
    "    return detokenize(ys, ind_tokens, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests, truths = [], []\n",
    "with open('../7. Testing/data.txt', 'r', encoding='utf8') as f:\n",
    "    while True:\n",
    "        t, t2 = f.readline(), f.readline()\n",
    "        if not t or not t2:\n",
    "            break\n",
    "        tests.append(unicodedata.normalize('NFKD', t).strip().lower().replace('q', \"'\"))\n",
    "        truths.append([split_tokens(t2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(predicts, truths):\n",
    "    correct, partial, wrong = 0, 0, 0\n",
    "    for i in range(len(predicts)):\n",
    "        if predicts[i] == truths[i][0]:\n",
    "            correct += 1\n",
    "        elif set(predicts[i]) & set(truths[i][0]):\n",
    "            partial += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "    return correct, partial, wrong\n",
    "\n",
    "def test_model(model, tests, truths, output):\n",
    "    predicts = []\n",
    "    # for i in tqdm(range(len(tests))):\n",
    "    #     predicts.append(split_tokens(translate([tests[i]], model)[0]))\n",
    "    with open(output, 'w', encoding='utf8') as f:\n",
    "        summary(model[0], input_size=(BATCH_SIZE, SRC_TOKEN_LEN, EMBEDDING_SIZE))\n",
    "        for i in range(1, 5):\n",
    "            f.write(f'BLEU w/ n-gram {i} : \\\n",
    "                {bleu_score(predicts, truths,max_n=i, weights=[1/i]*i)*100}\\\n",
    "            \\n')\n",
    "        correct, partial, wrong = similarity_score(predicts, truths)\n",
    "        f.write(f'Correct : {correct} ({correct/(correct+partial+wrong)*100})\\n')\n",
    "        f.write(f'Partial : {partial} ({partial/(correct+partial+wrong)*100})\\n')\n",
    "        f.write(f'Wrong   : {wrong} ({wrong/(correct+partial+wrong)*100})\\n')\n",
    "        f.write(f'Total   : {correct+partial+wrong}\\n')\n",
    "        f.write('\\n')\n",
    "        for i in range(len(predicts)):\n",
    "            f.write(f'Question: {tests[i]}\\n')\n",
    "            f.write(f'Truth   : {\" \".join(truths[i][0])}\\n')\n",
    "            f.write(f'Answer  : {\" \".join(predicts[i])}\\n')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2571,  1.6053,  0.5552],\n",
       "         [ 0.6493, -0.3217, -1.2847]]),\n",
       " tensor([[-1.8241, -0.4760, -1.5261],\n",
       "         [-0.4209, -1.3918, -2.3549]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import LogSoftmax\n",
    "\n",
    "m = LogSoftmax(dim=-1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)\n",
    "input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch_m1/lib/python3.9/site-packages/torchinfo/torchinfo.py:287\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> 287\u001b[0m     _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mto(device)(\u001b[39m*\u001b[39;49mx, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    288\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch_m1/lib/python3.9/site-packages/torch/nn/modules/module.py:1208\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> 1208\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 3 required positional arguments: 'tgt', 'src_mask', and 'tgt_mask'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m SRC_VOCAB_LEN, DST_VOCAB_LEN, SRC_TOKEN_LEN \u001b[39m=\u001b[39m \u001b[39m30994\u001b[39m, \u001b[39m14972\u001b[39m, \u001b[39m24\u001b[39m\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m load_model_embedding(\u001b[39m'\u001b[39m\u001b[39m../5. Embedding/embedding_base.h5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m./model_high_base.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m test_model(model, tests, truths, \u001b[39m'\u001b[39;49m\u001b[39m./result_high_base.txt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [11], line 17\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, tests, truths, output)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# for i in tqdm(range(len(tests))):\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#     predicts.append(split_tokens(translate([tests[i]], model)[0]))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(output, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 17\u001b[0m     summary(model[\u001b[39m0\u001b[39;49m], input_size\u001b[39m=\u001b[39;49m(BATCH_SIZE, SRC_TOKEN_LEN, EMBEDDING_SIZE))\n\u001b[1;32m     18\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m     19\u001b[0m         f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBLEU w/ n-gram \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m : \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m            \u001b[39m\u001b[39m{\u001b[39;00mbleu_score(predicts, truths,max_n\u001b[39m=\u001b[39mi, weights\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m\u001b[39m/\u001b[39mi]\u001b[39m*\u001b[39mi)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch_m1/lib/python3.9/site-packages/torchinfo/torchinfo.py:217\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m validate_user_params(\n\u001b[1;32m    211\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    212\u001b[0m )\n\u001b[1;32m    214\u001b[0m x, correct_input_size \u001b[39m=\u001b[39m process_input(\n\u001b[1;32m    215\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    216\u001b[0m )\n\u001b[0;32m--> 217\u001b[0m summary_list \u001b[39m=\u001b[39m forward_pass(\n\u001b[1;32m    218\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    219\u001b[0m )\n\u001b[1;32m    220\u001b[0m formatting \u001b[39m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    221\u001b[0m results \u001b[39m=\u001b[39m ModelStatistics(\n\u001b[1;32m    222\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    223\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch_m1/lib/python3.9/site-packages/torchinfo/torchinfo.py:296\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    295\u001b[0m     executed_layers \u001b[39m=\u001b[39m [layer \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m summary_list \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mexecuted]\n\u001b[0;32m--> 296\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    297\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecuted layers up to: \u001b[39m\u001b[39m{\u001b[39;00mexecuted_layers\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE, EPOCH, EMBEDDING_SIZE, PAD_TOKEN, DEVICE = 200, 500, 512, 2, 'cpu'\n",
    "N, D_FF, HEAD, DROPOUT, LABEL_SMOOTHING, LR_MODE = 6, 2048, 8, 0.1, 0.1, 'warmup'\n",
    "SRC_VOCAB_LEN, DST_VOCAB_LEN, SRC_TOKEN_LEN = 30994, 14972, 24\n",
    "model = load_model_embedding('../5. Embedding/embedding_base.h5', './model_high_base.h5')\n",
    "test_model(model, tests, truths, './result_high_base.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:42<00:00,  6.61it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE, EPOCH, EMBEDDING_SIZE, PAD_TOKEN, DEVICE = 200, 500, 512, 2, 'cpu'\n",
    "N, D_FF, HEAD, DROPOUT, LABEL_SMOOTHING, LR_MODE = 6, 2048, 8, 0.1, 0.1, 'warmup'\n",
    "SRC_VOCAB_LEN, DST_VOCAB_LEN, SRC_TOKEN_LEN = 8004, 8004, 24\n",
    "model = load_model_embedding('../5. Embedding/embedding_wp8k.h5', './model_high_wp8k.h5')\n",
    "test_model(model, tests, truths, './result_high_wp8k.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:43<00:00,  6.58it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE, EPOCH, EMBEDDING_SIZE, PAD_TOKEN, DEVICE = 200, 500, 256, 2, 'cpu'\n",
    "N, D_FF, HEAD, DROPOUT, LABEL_SMOOTHING, LR_MODE = 6, 2048, 2, 0.3, 0.1, 'decay'\n",
    "SRC_VOCAB_LEN, DST_VOCAB_LEN, SRC_TOKEN_LEN = 30994, 14972, 24\n",
    "model = load_model_embedding('../5. Embedding/embedding_base.h5', './model_low_base.h5')\n",
    "test_model(model, tests, truths, './result_low_base.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:02<00:00, 101.71it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE, EPOCH, EMBEDDING_SIZE, PAD_TOKEN, DEVICE = 200, 500, 256, 2, 'cpu'\n",
    "N, D_FF, HEAD, DROPOUT, LABEL_SMOOTHING, LR_MODE = 6, 2048, 2, 0.3, 0.1, 'decay'\n",
    "SRC_VOCAB_LEN, DST_VOCAB_LEN, SRC_TOKEN_LEN = 8004, 8004, 36\n",
    "model = load_model_embedding('../5. Embedding/embedding_wp8k.h5', './model_low_wp8k.h5')\n",
    "test_model(model, tests, truths, './result_low_wp8k.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_tokenized ['[UNK]', 'è', '[UNK]', 'tèdung', \"sèngko'\"]\n",
      "src_indexed [0, 3, 100, 3, 10752, 19, 1]\n",
      "dst_indexed tensor([ 0, 16,  1])\n",
      "dst_tokenized ['saya']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['saya']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate([\"dâpa' è dissa' tèdung sèngko'\"], model, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total known words: 486\n",
      "Total unknown words: 393\n",
      "Total words: 879\n",
      "Average words per sentence: 5.816901408450704, Max words: 28, Min words: 1\n",
      "Percentage of unknown words: 27.72397094430993%, 458 of 1652 words\n",
      "Percentage of sentences with unknown words: 80.98591549295774%, 230 of 284 sentences\n"
     ]
    }
   ],
   "source": [
    "# Find total unknown words\n",
    "known_words, unknown_words, words_len, count_unk, count_tot, count_cov = set(), set(), list(), 0, 0, 0\n",
    "for test in tests:\n",
    "    words = split_tokens(test)\n",
    "    words_len.append(len(words))\n",
    "    has_unk = False\n",
    "    for word in words:\n",
    "        count_tot += 1\n",
    "        if word.encode('utf-8') in model[1]:\n",
    "            known_words.add(word)\n",
    "        else:\n",
    "            count_unk += 1\n",
    "            unknown_words.add(word)\n",
    "            has_unk = True\n",
    "    if has_unk:\n",
    "        count_cov += 1\n",
    "print(f'Total known words: {len(known_words)}')\n",
    "print(f'Total unknown words: {len(unknown_words)}')\n",
    "print(f'Total words: {len(known_words) + len(unknown_words)}')\n",
    "print(f'Average words per sentence: {sum(words_len)/len(words_len)}, Max words: {max(words_len)}, Min words: {min(words_len)}')\n",
    "print(f'Percentage of unknown words: {count_unk/count_tot*100}%, {count_unk} of {count_tot} words')\n",
    "print(f'Percentage of sentences with unknown words: {count_cov/len(tests)*100}%, {count_cov} of {len(tests)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.552901023890785"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "486/879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['tidak',\n",
       "   'antara',\n",
       "   'lama',\n",
       "   'yang',\n",
       "   'kedua',\n",
       "   'lalu',\n",
       "   'bingung',\n",
       "   'tidak',\n",
       "   'mendapatkan',\n",
       "   '\"bhat-bhadhan\"',\n",
       "   ',',\n",
       "   '',\n",
       "   '.',\n",
       "   '',\n",
       "   '.',\n",
       "   '',\n",
       "   '.',\n",
       "   '',\n",
       "   ',',\n",
       "   'lalu',\n",
       "   'tiada',\n",
       "   'sebiji',\n",
       "   'pun',\n",
       "   'yang',\n",
       "   'kelihatan']]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in truths if '' in x[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('torch_m1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "119f89536cc47397180d31b7571c1053f63887a15e8165a80c120a7a49737c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
