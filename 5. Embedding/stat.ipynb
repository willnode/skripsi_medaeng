{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAD': {'token': array(['[BOS]', '[EOS]', '[PAD]', ..., b'pocar',\n",
       "         b'nyad\\xcc\\xa3iya\\xcc\\x82', b'katett'], dtype=object),\n",
       "  'embedding': {256: {'state': OrderedDict([('out_embed.weight',\n",
       "                  tensor([[ 7.2680e-01,  5.1928e-01, -2.7597e-01,  ...,  6.1708e-02,\n",
       "                            4.8969e-01,  6.6725e-01],\n",
       "                          [ 2.8069e-01, -4.2986e-01,  1.2414e-01,  ..., -1.1781e-01,\n",
       "                            2.2837e-02, -5.4550e-01],\n",
       "                          [-4.5124e-02,  4.7935e-02, -1.6432e-01,  ...,  7.6523e-02,\n",
       "                           -1.9193e-03,  5.4328e-02],\n",
       "                          ...,\n",
       "                          [ 8.3232e-01,  2.0386e-01,  6.8279e-01,  ..., -7.3159e-01,\n",
       "                            1.1092e-01,  7.8506e-01],\n",
       "                          [-4.0932e-01, -8.9507e-01,  4.4445e-01,  ...,  6.9816e-02,\n",
       "                           -1.3185e-04,  6.0232e-01],\n",
       "                          [ 1.0508e-01, -1.6288e-01,  4.7597e-01,  ..., -2.7727e-01,\n",
       "                           -3.3988e-01,  8.3864e-01]])),\n",
       "                 ('in_embed.weight',\n",
       "                  tensor([[-0.7297,  0.9287, -0.3385,  ..., -0.9452,  0.2404, -0.8057],\n",
       "                          [ 0.1765, -0.7783, -0.8310,  ..., -0.9242,  0.8891, -0.1891],\n",
       "                          [ 0.3353,  0.5537,  0.2581,  ..., -0.8624, -0.1748, -0.7005],\n",
       "                          ...,\n",
       "                          [ 0.4708,  0.2443,  0.0888,  ...,  0.1567, -0.3754,  0.0848],\n",
       "                          [-0.0201,  0.1267, -1.3645,  ..., -0.0750, -0.9692, -0.8670],\n",
       "                          [ 0.3177, -0.1805, -0.3162,  ..., -0.5001, -0.2127,  0.0758]]))]),\n",
       "    'optimizer': {'state': {0: {'momentum_buffer': None},\n",
       "      1: {'momentum_buffer': None}},\n",
       "     'param_groups': [{'lr': 0.0,\n",
       "       'momentum': 0,\n",
       "       'dampening': 0,\n",
       "       'weight_decay': 0,\n",
       "       'nesterov': False,\n",
       "       'maximize': False,\n",
       "       'foreach': None,\n",
       "       'initial_lr': 1,\n",
       "       'params': [0, 1]}]},\n",
       "    'scheduler': {'start_factor': 1,\n",
       "     'end_factor': 0,\n",
       "     'total_iters': 585000,\n",
       "     'base_lrs': [1],\n",
       "     'last_epoch': 1170000,\n",
       "     '_step_count': 1170001,\n",
       "     'verbose': False,\n",
       "     '_get_lr_called_within_step': False,\n",
       "     '_last_lr': [0.0]},\n",
       "    'epoch': 10000},\n",
       "   512: {'state': OrderedDict([('out_embed.weight',\n",
       "                  tensor([[ 5.1061e-02,  9.8469e-01,  7.6147e-01,  ..., -3.2947e-01,\n",
       "                            7.2399e-01,  5.3972e-01],\n",
       "                          [-4.2305e-01,  7.4569e-01,  6.4961e-01,  ..., -6.7395e-01,\n",
       "                           -1.4025e-01, -4.2031e-01],\n",
       "                          [ 3.4942e-04, -7.6811e-02, -6.2486e-02,  ...,  2.1991e-02,\n",
       "                            4.7339e-03, -8.1698e-02],\n",
       "                          ...,\n",
       "                          [-2.4602e-01, -4.6087e-01,  3.6948e-01,  ..., -7.0784e-01,\n",
       "                           -2.0751e-01,  8.5460e-01],\n",
       "                          [-4.7750e-01, -7.0883e-01,  6.1583e-02,  ...,  7.7102e-01,\n",
       "                           -2.3914e-01,  9.3677e-01],\n",
       "                          [ 6.3702e-01, -1.1763e-01,  2.2255e-01,  ...,  4.8476e-01,\n",
       "                           -9.2325e-01, -4.0794e-01]])),\n",
       "                 ('in_embed.weight',\n",
       "                  tensor([[ 0.4124, -0.9762, -0.6924,  ...,  0.6431, -0.7872,  0.9394],\n",
       "                          [-0.7561,  0.1480,  0.1603,  ...,  0.1005,  0.2564, -0.2930],\n",
       "                          [-0.4197, -0.3582, -0.2196,  ..., -0.2176, -0.3787,  0.9281],\n",
       "                          ...,\n",
       "                          [-0.9479,  0.2923, -0.6530,  ..., -0.2860, -0.2033,  0.5675],\n",
       "                          [-0.8227, -0.5548,  0.5937,  ...,  0.0146, -0.1733,  0.2976],\n",
       "                          [ 0.2012, -0.1366,  0.1698,  ..., -0.1878, -0.4445,  0.7353]]))]),\n",
       "    'optimizer': {'state': {0: {'momentum_buffer': None},\n",
       "      1: {'momentum_buffer': None}},\n",
       "     'param_groups': [{'lr': 0.0,\n",
       "       'momentum': 0,\n",
       "       'dampening': 0,\n",
       "       'weight_decay': 0,\n",
       "       'nesterov': False,\n",
       "       'maximize': False,\n",
       "       'foreach': None,\n",
       "       'initial_lr': 1,\n",
       "       'params': [0, 1]}]},\n",
       "    'scheduler': {'start_factor': 1,\n",
       "     'end_factor': 0,\n",
       "     'total_iters': 585000,\n",
       "     'base_lrs': [1],\n",
       "     'last_epoch': 1170000,\n",
       "     '_step_count': 1170001,\n",
       "     'verbose': False,\n",
       "     '_get_lr_called_within_step': False,\n",
       "     '_last_lr': [0.0]},\n",
       "    'epoch': 10000}}},\n",
       " 'IND': {'token': array(['[BOS]', '[EOS]', '[PAD]', ..., b'samud', b'belud', b'disud'],\n",
       "        dtype=object),\n",
       "  'embedding': {256: {'state': OrderedDict([('out_embed.weight',\n",
       "                  tensor([[ 0.6527, -0.1582,  0.7902,  ...,  0.6031, -0.2174, -0.4007],\n",
       "                          [ 0.7640,  0.4201,  0.5984,  ..., -0.8804,  0.0593,  0.3865],\n",
       "                          [-0.0524, -0.0085,  0.0394,  ..., -0.0138, -0.1445, -0.0603],\n",
       "                          ...,\n",
       "                          [ 0.8085,  0.5469,  0.5476,  ...,  0.7772,  0.3617, -0.2835],\n",
       "                          [ 0.4594, -0.8151,  0.3215,  ...,  0.1625,  0.1638, -0.1602],\n",
       "                          [-0.3805, -0.2900, -0.4878,  ...,  0.1445, -0.9230, -0.9401]])),\n",
       "                 ('in_embed.weight',\n",
       "                  tensor([[-0.9676, -0.2573,  0.6476,  ..., -0.3170, -0.6828,  0.2969],\n",
       "                          [-0.7998,  0.2921,  0.0221,  ...,  0.7291,  0.0395, -0.6899],\n",
       "                          [ 0.0547, -0.4679, -0.0066,  ...,  0.8873,  0.7032,  0.0703],\n",
       "                          ...,\n",
       "                          [ 0.4738, -0.1855, -0.0252,  ...,  0.9437,  0.1791,  0.0316],\n",
       "                          [ 0.4192,  0.6457,  0.6761,  ...,  0.4823, -0.7180, -0.3913],\n",
       "                          [-0.3066,  0.2577,  0.1800,  ...,  0.1065, -0.3208, -0.9855]]))]),\n",
       "    'optimizer': {'state': {0: {'momentum_buffer': None},\n",
       "      1: {'momentum_buffer': None}},\n",
       "     'param_groups': [{'lr': 0.0,\n",
       "       'momentum': 0,\n",
       "       'dampening': 0,\n",
       "       'weight_decay': 0,\n",
       "       'nesterov': False,\n",
       "       'maximize': False,\n",
       "       'foreach': None,\n",
       "       'initial_lr': 1,\n",
       "       'params': [0, 1]}]},\n",
       "    'scheduler': {'start_factor': 1,\n",
       "     'end_factor': 0,\n",
       "     'total_iters': 530000,\n",
       "     'base_lrs': [1],\n",
       "     'last_epoch': 1060000,\n",
       "     '_step_count': 1060001,\n",
       "     'verbose': False,\n",
       "     '_get_lr_called_within_step': False,\n",
       "     '_last_lr': [0.0]},\n",
       "    'epoch': 10000},\n",
       "   512: {'state': OrderedDict([('out_embed.weight',\n",
       "                  tensor([[ 0.7319, -0.3042, -0.2583,  ..., -0.8441,  0.3886, -0.3261],\n",
       "                          [ 0.5160, -0.7193,  0.5715,  ..., -0.3391, -0.6273, -0.8598],\n",
       "                          [-0.0141,  0.0056,  0.0604,  ...,  0.0834, -0.0503,  0.0431],\n",
       "                          ...,\n",
       "                          [ 0.3921,  0.3501, -0.7314,  ...,  0.4866, -0.7412,  0.6463],\n",
       "                          [ 0.2494, -0.3364, -1.0205,  ..., -0.3882, -0.6913,  0.7862],\n",
       "                          [-0.8079, -0.3249, -0.3811,  ...,  0.0664,  0.6930, -0.1667]])),\n",
       "                 ('in_embed.weight',\n",
       "                  tensor([[ 0.3837,  0.2956,  0.6786,  ...,  0.5566, -0.9594,  0.0331],\n",
       "                          [-0.5059,  0.1896, -0.1715,  ...,  0.4099,  0.0348,  0.5352],\n",
       "                          [-0.4276, -0.9633,  0.5088,  ...,  0.4370, -0.2250,  0.5147],\n",
       "                          ...,\n",
       "                          [ 0.1205,  0.6522,  0.3279,  ...,  0.4094, -0.6953, -0.4485],\n",
       "                          [-1.0409,  0.0502,  0.8081,  ...,  0.4333, -0.9692,  0.3088],\n",
       "                          [-0.1574,  0.3710, -0.3070,  ...,  0.0945, -0.2838,  0.4178]]))]),\n",
       "    'optimizer': {'state': {0: {'momentum_buffer': None},\n",
       "      1: {'momentum_buffer': None}},\n",
       "     'param_groups': [{'lr': 0.0,\n",
       "       'momentum': 0,\n",
       "       'dampening': 0,\n",
       "       'weight_decay': 0,\n",
       "       'nesterov': False,\n",
       "       'maximize': False,\n",
       "       'foreach': None,\n",
       "       'initial_lr': 1,\n",
       "       'params': [0, 1]}]},\n",
       "    'scheduler': {'start_factor': 1,\n",
       "     'end_factor': 0,\n",
       "     'total_iters': 530000,\n",
       "     'base_lrs': [1],\n",
       "     'last_epoch': 1060000,\n",
       "     '_step_count': 1060001,\n",
       "     'verbose': False,\n",
       "     '_get_lr_called_within_step': False,\n",
       "     '_last_lr': [0.0]},\n",
       "    'epoch': 10000}}},\n",
       " 'TEKS': array([[[   0, 7915,    1, ...,    2,    2,    2],\n",
       "         [   0, 1089,    1, ...,    2,    2,    2]],\n",
       " \n",
       "        [[   0, 6437,  115, ...,    2,    2,    2],\n",
       "         [   0, 1106, 1178, ...,    2,    2,    2]],\n",
       " \n",
       "        [[   0,  476,   17, ...,    2,    2,    2],\n",
       "         [   0, 3220,    8, ...,    2,    2,    2]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   0,   71,   27, ...,    2,    2,    2],\n",
       "         [   0,   55,   21, ...,    2,    2,    2]],\n",
       " \n",
       "        [[   0,   71,   27, ...,    2,    2,    2],\n",
       "         [   0, 3268,   17, ...,    2,    2,    2]],\n",
       " \n",
       "        [[   0,   71,   27, ...,    2,    2,    2],\n",
       "         [   0,   55,   21, ...,    2,    2,    2]]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.load('embedding_wp8k.h5', map_location=torch.device('cpu'))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4124, -0.9762, -0.6924,  ...,  0.6431, -0.7872,  0.9394],\n",
       "        [-0.7561,  0.1480,  0.1603,  ...,  0.1005,  0.2564, -0.2930],\n",
       "        [-0.4197, -0.3582, -0.2196,  ..., -0.2176, -0.3787,  0.9281],\n",
       "        ...,\n",
       "        [-0.9479,  0.2923, -0.6530,  ..., -0.2860, -0.2033,  0.5675],\n",
       "        [-0.8227, -0.5548,  0.5937,  ...,  0.0146, -0.1733,  0.2976],\n",
       "        [ 0.2012, -0.1366,  0.1698,  ..., -0.1878, -0.4445,  0.7353]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['MAD']['embedding'][512]['state']['in_embed.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8004"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['IND']['embedding'][512]['state']['in_embed.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['abâ', '_lâ'], ['meny', '_am', '_p', '_aikan'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = f['TEKS'][2800]\n",
    "[f['MAD']['token'][x].decode(\"utf-8\") for x in t[0] if x >= 4], \\\n",
    "[f['IND']['token'][x].decode(\"utf-8\") for x in t[1] if x >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df3e798977ef176ae40ba434fe314604276c5edc4011c2bf07ae697b2eaa45af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
