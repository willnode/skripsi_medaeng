{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAD': {'token': array(['[BOS]', '[EOS]', '[PAD]', ..., b'buk', b'bukoh', b'akon'],\n",
       "        dtype=object),\n",
       "  'embedding': {256: {'state': OrderedDict([('out_embed.weight',\n",
       "                  tensor([[ 0.2864, -0.1880,  0.4790,  ..., -0.6662,  0.2594,  0.2970],\n",
       "                          [ 0.4400,  0.3668, -0.7854,  ...,  0.2977,  0.3648,  0.3609],\n",
       "                          [ 0.0272, -0.1218,  0.0727,  ..., -0.0525,  0.0379, -0.0847],\n",
       "                          ...,\n",
       "                          [-0.0176,  0.9952, -0.7156,  ..., -0.1078,  0.2166,  0.0465],\n",
       "                          [-0.5162,  0.3528, -0.1197,  ...,  0.4175,  0.1526, -0.5871],\n",
       "                          [ 0.5072, -0.8843, -0.0355,  ..., -0.9969,  0.1043,  0.7853]])),\n",
       "                 ('in_embed.weight',\n",
       "                  tensor([[ 0.5008,  0.8122, -0.2001,  ..., -0.1233, -0.7974,  0.1168],\n",
       "                          [ 0.8682,  0.6445, -0.0164,  ...,  0.3475, -0.5600,  0.3920],\n",
       "                          [ 0.6040, -0.0240, -0.2540,  ..., -0.3634,  0.0978,  0.8423],\n",
       "                          ...,\n",
       "                          [-0.4686, -0.7392,  0.7556,  ..., -1.4464, -0.0969, -0.4788],\n",
       "                          [-0.3955,  0.3124,  0.5149,  ...,  0.2631,  0.6391, -0.1445],\n",
       "                          [ 0.9993, -0.1878,  0.1759,  ..., -0.2187,  0.6773, -0.4244]]))]),\n",
       "    'optimizer': {'state': {0: {'momentum_buffer': None},\n",
       "      1: {'momentum_buffer': None}},\n",
       "     'param_groups': [{'lr': 0.0,\n",
       "       'momentum': 0,\n",
       "       'dampening': 0,\n",
       "       'weight_decay': 0,\n",
       "       'nesterov': False,\n",
       "       'maximize': False,\n",
       "       'foreach': None,\n",
       "       'initial_lr': 1,\n",
       "       'params': [0, 1]}]},\n",
       "    'scheduler': {'start_factor': 1,\n",
       "     'end_factor': 0,\n",
       "     'total_iters': 11000000,\n",
       "     'base_lrs': [1],\n",
       "     'last_epoch': 11000000,\n",
       "     '_step_count': 11000001,\n",
       "     'verbose': False,\n",
       "     '_get_lr_called_within_step': False,\n",
       "     '_last_lr': [0.0]},\n",
       "    'epoch': 100000},\n",
       "   512: {'state': OrderedDict([('out_embed.weight',\n",
       "                  tensor([[ 0.5617, -0.6327,  0.6351,  ...,  0.2749, -0.5700,  0.8672],\n",
       "                          [-0.4546, -0.1531,  0.6231,  ..., -0.4260,  0.6534,  0.7028],\n",
       "                          [-0.1163,  0.0654,  0.0839,  ...,  0.1181, -0.1884, -0.0639],\n",
       "                          ...,\n",
       "                          [-0.1124,  0.0324, -0.6221,  ...,  0.2884,  0.6700, -1.2259],\n",
       "                          [-0.8443,  0.9609, -0.1521,  ..., -0.3721, -0.1469, -0.2234],\n",
       "                          [ 0.8150, -0.4113, -0.4688,  ..., -0.7427, -0.1721,  0.5810]])),\n",
       "                 ('in_embed.weight',\n",
       "                  tensor([[ 0.2013,  0.0599, -0.5636,  ..., -0.9809, -0.0742, -0.9718],\n",
       "                          [ 0.4336,  0.2279,  0.7211,  ...,  0.5350,  0.9851, -0.0799],\n",
       "                          [-0.8662, -0.6195, -0.0163,  ..., -0.3977,  0.2754,  0.5548],\n",
       "                          ...,\n",
       "                          [-0.2075, -0.3110, -0.3013,  ...,  0.6450, -1.4559, -0.2960],\n",
       "                          [ 0.2286,  0.9402, -0.6818,  ...,  0.3404,  0.3274,  0.1785],\n",
       "                          [ 0.5539, -0.5770, -0.7320,  ..., -0.1426, -0.4321,  0.3029]]))]),\n",
       "    'optimizer': {'state': {0: {'momentum_buffer': None},\n",
       "      1: {'momentum_buffer': None}},\n",
       "     'param_groups': [{'lr': 0.17736981816206263,\n",
       "       'momentum': 0,\n",
       "       'dampening': 0,\n",
       "       'weight_decay': 0,\n",
       "       'nesterov': False,\n",
       "       'maximize': False,\n",
       "       'foreach': None,\n",
       "       'initial_lr': 1,\n",
       "       'params': [0, 1]}]},\n",
       "    'scheduler': {'start_factor': 1,\n",
       "     'end_factor': 0,\n",
       "     'total_iters': 11000000,\n",
       "     'base_lrs': [1],\n",
       "     'last_epoch': 9048932,\n",
       "     '_step_count': 9048933,\n",
       "     'verbose': False,\n",
       "     '_get_lr_called_within_step': False,\n",
       "     '_last_lr': [0.17736981816206263]},\n",
       "    'epoch': 82263}}},\n",
       " 'IND': {'token': array(['[BOS]', '[EOS]', '[PAD]', ..., b'bertarung', b'menyarung',\n",
       "         b'larung'], dtype=object),\n",
       "  'embedding': {256: {'state': OrderedDict([('out_embed.weight',\n",
       "                  tensor([[ 0.9393, -0.3310, -0.4653,  ..., -0.1745, -0.4179, -0.2996],\n",
       "                          [ 0.4978, -0.7515, -0.3794,  ..., -0.4560,  0.3189, -0.2563],\n",
       "                          [-0.0078,  0.0139,  0.0453,  ..., -0.0552,  0.1380,  0.0940],\n",
       "                          ...,\n",
       "                          [ 0.7341, -0.9824,  0.5022,  ..., -0.1471,  0.6229, -0.3323],\n",
       "                          [ 1.0108, -0.1595,  0.2864,  ..., -0.2160,  0.4662,  0.6214],\n",
       "                          [-0.8815,  0.0192,  0.4418,  ...,  0.1335, -0.6073,  0.8877]])),\n",
       "                 ('in_embed.weight',\n",
       "                  tensor([[-0.1314, -0.0214, -0.4931,  ...,  0.6877, -0.1790,  0.9205],\n",
       "                          [ 0.1283,  0.7870, -0.3447,  ...,  0.3437,  0.5619, -0.0448],\n",
       "                          [-0.9119, -0.5935,  0.9637,  ..., -0.2988, -0.6626,  0.7146],\n",
       "                          ...,\n",
       "                          [ 0.0986, -0.5882,  0.7402,  ..., -0.2229,  0.0338, -0.2753],\n",
       "                          [-0.4997, -0.1419, -0.3576,  ...,  0.2183,  0.1670,  0.1635],\n",
       "                          [ 0.4348,  0.6915,  0.0125,  ...,  0.3820, -0.0780, -0.2435]]))]),\n",
       "    'optimizer': {'state': {0: {'momentum_buffer': None},\n",
       "      1: {'momentum_buffer': None}},\n",
       "     'param_groups': [{'lr': 0.0,\n",
       "       'momentum': 0,\n",
       "       'dampening': 0,\n",
       "       'weight_decay': 0,\n",
       "       'nesterov': False,\n",
       "       'maximize': False,\n",
       "       'foreach': None,\n",
       "       'initial_lr': 1,\n",
       "       'params': [0, 1]}]},\n",
       "    'scheduler': {'start_factor': 1,\n",
       "     'end_factor': 0,\n",
       "     'total_iters': 8900000,\n",
       "     'base_lrs': [1],\n",
       "     'last_epoch': 8900000,\n",
       "     '_step_count': 8900001,\n",
       "     'verbose': False,\n",
       "     '_get_lr_called_within_step': False,\n",
       "     '_last_lr': [0.0]},\n",
       "    'epoch': 100000},\n",
       "   512: {'state': OrderedDict([('out_embed.weight',\n",
       "                  tensor([[ 0.1537,  0.3620,  0.5361,  ...,  0.3684,  1.1658, -0.3786],\n",
       "                          [ 0.2479, -0.7988,  0.4599,  ...,  1.0407,  0.3302, -0.5828],\n",
       "                          [ 0.0258,  0.1601, -0.0069,  ..., -0.0155, -0.1953,  0.0925],\n",
       "                          ...,\n",
       "                          [ 0.9644, -0.5160,  0.5676,  ...,  0.9444, -0.1817, -0.4664],\n",
       "                          [ 0.3610, -0.9290, -0.8450,  ..., -0.1827, -0.4462,  0.3481],\n",
       "                          [ 0.1409,  0.8485,  0.7254,  ..., -0.2490, -0.9237, -0.4873]])),\n",
       "                 ('in_embed.weight',\n",
       "                  tensor([[ 0.3317,  0.3775, -0.6463,  ...,  0.4929, -0.3749,  0.5235],\n",
       "                          [-0.6250,  0.5817,  0.5815,  ...,  0.3511, -0.8704, -0.3408],\n",
       "                          [ 0.0012,  0.1909,  0.1839,  ...,  0.1596, -0.3096,  0.3144],\n",
       "                          ...,\n",
       "                          [-0.8512,  0.0457, -0.5539,  ..., -0.9031,  0.4292,  0.1364],\n",
       "                          [-0.2743,  0.2691,  0.4807,  ...,  0.0946, -0.6814, -0.0505],\n",
       "                          [-0.6529, -0.2141,  0.4665,  ...,  0.1688, -0.0880, -0.3142]]))]),\n",
       "    'optimizer': {'state': {0: {'momentum_buffer': None},\n",
       "      1: {'momentum_buffer': None}},\n",
       "     'param_groups': [{'lr': 0.12218797753775486,\n",
       "       'momentum': 0,\n",
       "       'dampening': 0,\n",
       "       'weight_decay': 0,\n",
       "       'nesterov': False,\n",
       "       'maximize': False,\n",
       "       'foreach': None,\n",
       "       'initial_lr': 1,\n",
       "       'params': [0, 1]}]},\n",
       "    'scheduler': {'start_factor': 1,\n",
       "     'end_factor': 0,\n",
       "     'total_iters': 8900000,\n",
       "     'base_lrs': [1],\n",
       "     'last_epoch': 7812527,\n",
       "     '_step_count': 7812528,\n",
       "     'verbose': False,\n",
       "     '_get_lr_called_within_step': False,\n",
       "     '_last_lr': [0.12218797753775486]},\n",
       "    'epoch': 87781}}},\n",
       " 'TEKS': array([[[   0,  868,  143, ...,    2,    2,    2],\n",
       "         [   0,  730,    1, ...,    2,    2,    2]],\n",
       " \n",
       "        [[   0, 3194,  116, ...,    2,    2,    2],\n",
       "         [   0, 4729,  113, ...,    2,    2,    2]],\n",
       " \n",
       "        [[   0,  818,   17, ...,    2,    2,    2],\n",
       "         [   0, 3993,    1, ...,    2,    2,    2]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   0, 6079,    1, ...,    2,    2,    2],\n",
       "         [   0, 4908,  113, ...,    2,    2,    2]],\n",
       " \n",
       "        [[   0,   73,   27, ...,    2,    2,    2],\n",
       "         [   0, 7597,  108, ...,    2,    2,    2]],\n",
       " \n",
       "        [[   0, 6079,    1, ...,    2,    2,    2],\n",
       "         [   0, 7597,  108, ...,    2,    2,    2]]], dtype=int32)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.load('embedding_wp8k.h5', map_location=torch.device('cpu'))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2013,  0.0599, -0.5636,  ..., -0.9809, -0.0742, -0.9718],\n",
       "        [ 0.4336,  0.2279,  0.7211,  ...,  0.5350,  0.9851, -0.0799],\n",
       "        [-0.8662, -0.6195, -0.0163,  ..., -0.3977,  0.2754,  0.5548],\n",
       "        ...,\n",
       "        [-0.2075, -0.3110, -0.3013,  ...,  0.6450, -1.4559, -0.2960],\n",
       "        [ 0.2286,  0.9402, -0.6818,  ...,  0.3404,  0.3274,  0.1785],\n",
       "        [ 0.5539, -0.5770, -0.7320,  ..., -0.1426, -0.4321,  0.3029]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['MAD']['embedding'][512]['state']['in_embed.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8004"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['IND']['embedding'][512]['state']['in_embed.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[BOS]',\n",
       "  b'd\\xcc\\xa3i',\n",
       "  b\"_'-\",\n",
       "  b'_an',\n",
       "  b\"_d\\xcc\\xa3i'\",\n",
       "  b'bha\\xcc\\x82ra\\xcc\\x82',\n",
       "  b'_ng',\n",
       "  b'se\\xcc\\x80',\n",
       "  b\"ta'\",\n",
       "  b'kenne\\xcc\\x80ng',\n",
       "  b'e\\xcc\\x80',\n",
       "  b'_angghuy',\n",
       "  '[EOS]'],\n",
       " ['[BOS]', b'tidak', b'melihat', '[EOS]'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = f['TEKS'][89]\n",
    "[f['MAD']['token'][x] for x in t[0] if x != 2], \\\n",
    "[f['IND']['token'][x] for x in t[1] if x != 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
